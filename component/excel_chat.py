import os

import pandas as pd
import streamlit as st
from PIL import Image
from loguru import logger
import openai

from .pipelines.excel_utils import CodeKernel, extract_code, execute


EXAMPLES = [
    "",
    "æœªæˆå¹´ä¹˜å®¢å æ¯”å¤šå°‘ï¼Ÿ",
    "ç”·æ€§ä¹˜å®¢çš„å¹³å‡å¹´é¾„æ˜¯å¤šå°‘ï¼Ÿ",
    "æœ‰å¤šå°‘äººæœ‰ 3 ä¸ªä»¥ä¸Šçš„å…„å¼Ÿå§å¦¹ï¼Ÿ",
    "å„ä¸ªç™»èˆ¹æ¸¯å£çš„äººæ•°æœ‰å¤šå°‘ï¼Ÿ",
    "å„ç­‰çº§å®¢èˆ±çš„å¹³å‡èˆ¹ç¥¨ä»·æ ¼æ˜¯å¤šå°‘ï¼Ÿ",
    "æŸ¥è¯¢å¹´é¾„æœ€å¤§çš„ä¹˜å®¢çš„ç™»èˆ¹ä¿¡æ¯",
]


@st.cache_resource
def save_file(df: pd.DataFrame, filename):
    df.to_excel(filename, index=False)
    return filename


@st.cache_resource
def get_kernel():
    return CodeKernel()


def get_system_messages(filename):
    PRESET_CODE = f"""
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import matplotlib as mpl

# # æ”¯æŒä¸­æ–‡
plt.rcParams['font.sans-serif'] = ['SimHei']  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
plt.rcParams['font.size'] = 18

# read data
df = pd.read_excel("{filename}")
"""
    code = PRESET_CODE + "df.info()"
    _, res = execute(code, get_kernel())

    SYSTEM_MESSAGE = [
        {
            "role": "system",
            "content": """ä½ æ˜¯ä¸€ä½æ™ºèƒ½AIåŠ©æ‰‹ï¼Œä½ å«"å®¡å…ƒå¤§æ¨¡å‹"ï¼Œä½ è¿æ¥ç€ä¸€å°ç”µè„‘ï¼Œä½†è¯·æ³¨æ„ä¸èƒ½è”ç½‘ã€‚åœ¨ä½¿ç”¨Pythonè§£å†³ä»»åŠ¡æ—¶ï¼Œä½ å¯ä»¥è¿è¡Œä»£ç å¹¶å¾—åˆ°ç»“æœï¼Œå¦‚æœè¿è¡Œç»“æœæœ‰é”™è¯¯ï¼Œä½ éœ€è¦å°½å¯èƒ½å¯¹ä»£ç è¿›è¡Œæ”¹è¿›ã€‚
    ä½ ä¸»è¦åŸºäº pandas åº“æ¥æ‰§è¡Œä»£ç å¹¶è¾“å‡ºç»“æœï¼Œä»¥æ­¤æ¥å›ç­”ç”¨æˆ·çš„ç›¸å…³é—®é¢˜ã€‚ç°åœ¨å·²ç»é€šè¿‡ pandas æ­£ç¡®åŠ è½½äº†æ•°æ®æ–‡ä»¶å¹¶åˆ›å»ºäº†åˆå§‹æ•°æ®æ¡† pd.DataFrameï¼Œå…¶åç§°ä¸º dfã€‚"""
        },
        {
            "role": "user",
            "content": "æŸ¥çœ‹ä¸€ä¸‹æ•°æ®æ¡† df çš„å…·ä½“ä¿¡æ¯"
        },
        {
            "role": "assistant",
            "content": f""" interpreter\nè¦æŸ¥çœ‹æ•°æ®æ¡† df çš„å…·ä½“ä¿¡æ¯ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ `info()` å‡½æ•°ã€‚

    ```python
    {code}
    ```
    """
        },
        {
            "role": "function",
            "content": res,
        },
        {
            "role": "assistant",
            "content": f"æ ¹æ®æŸ¥è¯¢ç»“æœï¼Œè¯¥æ•°æ®æ¡†çš„å…·ä½“ä¿¡æ¯ä¸ºï¼š\n{res}"
        },
    ]

    code = PRESET_CODE + "df.head(2)"
    _, res = execute(code, get_kernel())
    SYSTEM_MESSAGE.extend(
        [
            {
                "role": "user",
                "content": "æŸ¥çœ‹æ•°æ®çš„å‰ä¸¤è¡Œ"
            },
            {
                "role": "assistant",
                "content": f""" interpreter\nè¦æŸ¥çœ‹æ•°æ®æ¡† df çš„å‰ä¸¤è¡Œï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ `head()` å‡½æ•°ã€‚

            ```python
            {code}
            ```
            """
            },
            {
                "role": "function",
                "content": res,
            },
            {
                "role": "assistant",
                "content": f"æ ¹æ®æŸ¥è¯¢ç»“æœï¼Œè¯¥æ•°æ®æ¡†çš„å‰ä¸¤è¡Œä¸ºï¼š\n{res}"
            },
        ]
    )
    return SYSTEM_MESSAGE, PRESET_CODE


def chat_once(preset_code: str, system_messages: list, query: str):
    params = dict(
        model="chatglm3",
        messages=system_messages + [{"role": "user", "content": query}],
        temperature=0,
    )
    openai.api_key = 'xxxx'
    openai.api_base = "http://192.168.20.59:7891/v1"
    response = openai.ChatCompletion.create(**params)
    content = response.choices[0].message.content
    if "interpreter" in content:
        logger.info(f"Interpreter Response: {content}")

        try:
            code = extract_code(content)
            logger.info(f"Interpreter Code: {code}")
            code = preset_code + code
            res_type, res = execute(code, get_kernel())
            logger.info(f"Observation Response: {res}")

            params["messages"].append(
                {
                    "role": "assistant",
                    "content": content
                }
            )

            if res_type == "image":
                return res
            else:
                params["messages"].append(
                    {
                        "role": "function",
                        "content": res,
                    }
                )
                return openai.ChatCompletion.create(**params, stream=True)

        except:
            return "æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”è¯¥é—®é¢˜ï¼Œè¯·æ‚¨å°è¯•åˆ«çš„é—®é¢˜ï¼"
    else:
        return content


@st.cache_resource
def load_excel(file_path):
    return pd.read_excel(file_path)


import time


def excel_chat():
    st.title("ğŸ’¬ è¡¨æ ¼é—®ç­”")
    if "messages" not in st.session_state:
        st.session_state.messages = []

    with st.sidebar:
        uploaded_file = st.file_uploader("è¯·åœ¨æ­¤å¤„ä¸Šä¼ excelæ–‡ä»¶",
                                         accept_multiple_files=False,
                                         type=['xlsx', 'xls'],
                                         )

        if uploaded_file is not None:
            with open(os.path.join('static/excel', uploaded_file.name), "wb") as f:
                f.write(uploaded_file.getbuffer())
            load_excel(os.path.join('static/excel', uploaded_file.name))
            st.success("Uploaded file: '{}'".format(uploaded_file.name))

        # é€‰æ‹©æ–‡ä»¶
        filename = st.selectbox('è¯·é€‰æ‹©ä¸€ä¸ªæ–‡ä»¶1ï¼š', sorted(os.listdir('static/excel'), reverse=True), )
        st.write('You selected: ', filename)

        col1, col2 = st.columns(2)
        with col1:
            if st.button('ğŸ—‘ï¸åˆ é™¤é€‰ä¸­æ–‡ä»¶', use_container_width=True, ):
                try:
                    os.remove(f'static/excel/{filename}')
                    st.success(f'æ–‡ä»¶ {filename} å·²è¢«åˆ é™¤ã€‚')
                    st.rerun()
                except Exception as e:
                    st.error(f'åˆ é™¤æ–‡ä»¶æ—¶å‡ºé”™: {e}')

        with col2:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºå†å²å¯¹è¯", use_container_width=True, ):
                st.session_state.messages = []

    file_path = os.path.join('static/excel', filename)
    df = load_excel(file_path)
    time.sleep(0.1)
    # åŠ è½½æ–‡ä»¶
    if len(df) != 0:
        with st.expander("DataFrame", False):
            st.dataframe(df)

        system_messages, preset_code = get_system_messages(file_path)

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                if isinstance(message["content"], str):
                    st.markdown(message["content"])
                else:
                    st.image(message["content"])

        if system_messages:
            if prompt := st.chat_input("ç¤ºä¾‹ï¼šè¯¥æ•°æ®é›†ä¸€å…±æœ‰å¤šå°‘ä¸ªæ ·æœ¬ï¼Ÿ", key="prompt"):
                with st.chat_message("user"):
                    st.markdown(prompt)
                st.session_state.messages.append(
                    {
                        "role": "user",
                        "content": prompt
                    }
                )

                with st.chat_message("assistant"):
                    with st.spinner('Wait...'):
                        response = chat_once(preset_code, system_messages, prompt)

                    if isinstance(response, str):
                        full_response = response
                        st.markdown(full_response)
                    elif isinstance(response, Image.Image):
                        full_response = response
                        st.image(full_response)
                    else:
                        message_placeholder = st.empty()
                        full_response = ""
                        for chunk in response:
                            full_response += chunk.choices[0].delta.get('content', "")

                            message_placeholder.markdown(full_response + "â–Œ")
                        message_placeholder.markdown(full_response)

                    st.session_state.messages.append(
                        {
                            "role": "assistant",
                            "content": full_response
                        }
                    )