import time
import os
import streamlit as st
import pandas as pd

from .pipelines.es import ElasticsearchServer
from .pipelines.utils import handle_response, create_message
from .pipelines.prompt import KNOWLEDGE_PROMPT, CHAT_EXAMPLES

BAICHUAN_URL = os.getenv("BAICHUAN_URL")


def handle_kb_qa(prompt, top_k, threshold):
    index_name = 'audit_index'
    es_server = ElasticsearchServer()
    # es_server.doc_upload(index_name=index_name)
    result = es_server.doc_search(index_name=index_name, query=prompt, top_k=top_k, method='hybrid',
                                  knn_boost=threshold)
    context = "\n".join([doc['content'] for doc in result])
    doc_prompt = KNOWLEDGE_PROMPT.format(query=prompt, context=context)
    reference = [
        {
            "text": doc['content'],
            "source": doc['source'],
            "score": float(doc['score'])
        }
        for doc in result
    ]
    return doc_prompt, reference, True


def knowledge_chat():
    with st.sidebar:
        # TODO: å¯¹è¯æ¨¡å‹ä¸ä¼šè¯ç»‘å®š
        def on_mode_change():
            st.session_state.messages = []
            mode = st.session_state.vec_modify
            text = f"å·²åˆ‡æ¢åˆ° {mode} æ¨¡å¼ã€‚"
            if mode == "çŸ¥è¯†åº“é—®ç­”":
                cur_kb = st.session_state.get("selected_kb")
                if cur_kb:
                    text = f"{text} å½“å‰çŸ¥è¯†åº“ï¼š `{cur_kb}`ã€‚"
            st.toast(text)

        # æ¨¡å‹å‚æ•°é€‰æ‹©
        temperature = st.slider("Temperatureï¼š", 0.0, 1.0, 0.7, 0.05)
        history_len = st.number_input("å†å²å¯¹è¯è½®æ•°ï¼š", 0, 10, 1)

        # çŸ¥è¯†åº“é…ç½®

        with st.expander("çŸ¥è¯†åº“é…ç½®", True):
            vec_modify = st.selectbox("è¯·é€‰æ‹©ç›¸ä¼¼åº¦æœç´¢æ¨¡å¼ï¼š",
                                      ["Elasticsearch",
                                       ],
                                      index=0,
                                      on_change=on_mode_change,
                                      key="vec_modify",
                                      )
            kb_top_k = st.number_input("åŒ¹é…çŸ¥è¯†æ¡æ•°ï¼š", 1, 6, 5)
            score_threshold = st.slider(
                f"{'çŸ¥è¯†åŒ¹é…åˆ†æ•°é˜ˆå€¼ï¼š' if vec_modify == 'Faisså‘é‡åº“' else 'è¯­ä¹‰å…³é”®å­—æƒé‡ï¼š(0:ä»£è¡¨ä»…ä½¿ç”¨å…³é”®å­—)'}ï¼š",
                0.0, 1.0, float(0.5), 0.01)

        # æ¸…ç©ºå¯¹è¯
        cols = st.columns(2)

        if cols[1].button(
                "æ¸…ç©ºå¯¹è¯",
                use_container_width=True,
        ):
            st.session_state.messages = []
            st.experimental_rerun()

    st.title("ğŸ’¬ å®¡è®¡çŸ¥è¯†åº“é—®ç­”")
    chat_input_placeholder = "è¯·è¾“å…¥å¯¹è¯å†…å®¹ï¼Œæ¢è¡Œè¯·ä½¿ç”¨Shift+Enter "
    df = pd.DataFrame({"ç¤ºä¾‹": CHAT_EXAMPLES})
    with st.expander("DataFrame", False):
        st.table(df)

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input(chat_input_placeholder, key="prompt"):

        full_response = ''
        with st.chat_message("user"):
            st.markdown(prompt)

        st.session_state.messages.append(create_message("user", prompt))
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            with st.spinner("æ€è€ƒä¸­..."):
                doc_prompt, reference, is_true = handle_kb_qa(prompt,
                                                              st.session_state.get("top_k", kb_top_k),
                                                              score_threshold)
            if is_true:
                full_response = handle_response([
                    {"role": st.session_state.messages[-1]["role"], "content": doc_prompt}], 0.1, 1,
                    message_placeholder)
                if reference is not None:
                    st.markdown("### Reference Documents")
                    st.json(reference, expanded=False)
            else:
                for item in doc_prompt:
                    full_response += item
                    message_placeholder.markdown(full_response + "â–Œ")
                    time.sleep(0.05)
                message_placeholder.markdown(full_response)
                reference = None
            st.session_state.messages.append(create_message("assistant", full_response, reference))
            st.success('Done!')