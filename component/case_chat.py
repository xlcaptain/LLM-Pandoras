import time
import copy
import requests
import streamlit as st
from .pipelines.process_data import loadtxt
from .pipelines.utils import handle_response, create_message
from .pipelines.prompt import CASE_PROMPT


content, labels, backends = loadtxt()
result = {}
for item in content:
    if item[0] in result:
        result[item[0]] += "{}çš„{}ä¸º{}".format(item[0], item[1], item[2])
    else:
        result[item[0]] = "{}çš„{}ä¸º{}".format(item[0], item[1], item[2])
result['å…¶ä»–'] = ''


def case_chat():

    with st.sidebar:
        # æ¨¡å‹å‚æ•°é€‰æ‹©
        temperature = st.slider("Temperatureï¼š", 0.0, 1.0, 0.7, 0.05)
        history_len = st.number_input("å†å²å¯¹è¯è½®æ•°ï¼š", 0, 10, 1)

        # æ¸…ç©ºå¯¹è¯
        cols = st.columns(2)

        if cols[1].button(
                "æ¸…ç©ºå¯¹è¯",
                use_container_width=True,
        ):
            st.session_state.messages = []
            st.experimental_rerun()

    # Display chat messages from history on app rerun
    st.title("ğŸ’¬å®¡è®¡æ¡ˆä¾‹é—®ç­”")
    chat_input_placeholder = "è¯·è¾“å…¥å¯¹è¯å†…å®¹ï¼Œæ¢è¡Œè¯·ä½¿ç”¨Shift+Enter "

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input(chat_input_placeholder, key="prompt"):
        full_response = ''
        with st.chat_message("user"):
            st.markdown(prompt)

        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            response = requests.post("http://192.168.20.59:9001/predict", json={'text': prompt})

            response = next(iter(response.json()))
            full_response = ''

            if response and response != 'å…¶ä»–':
                tmp = copy.deepcopy(st.session_state.messages)
                for i in reversed(range(len(tmp))):
                    if tmp[i]['role'] == 'user':
                        tmp[i]['content'] = CASE_PROMPT.format(query=prompt, context=result[response])
                        break
                full_response = handle_response(tmp, temperature, history_len,
                                                message_placeholder)
                st.markdown("### Reference Documents")
                st.json({'text': result[response], 'type': response}, expanded=False)

            else:
                for response in list('å¯¹ä¸èµ·ï¼Œæˆ‘æ— æ³•è¯†åˆ«ä½ çš„æ¡ˆä¾‹ç±»å‹ï¼Œæ‰€ä»¥æ— æ³•å›ç­”ä½ çš„é—®é¢˜ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚'):
                    full_response += response
                    time.sleep(0.05)
                    message_placeholder.markdown(full_response + "â–Œ")
                message_placeholder.markdown(full_response)

            st.session_state.messages.append(create_message("assistant", full_response))